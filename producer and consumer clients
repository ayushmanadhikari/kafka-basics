Producer

Constructing a Kafka Producer
-bootstrap.servers
.list of host:port of brokers that producer will use to establish connection to the Kafka cluster

-key.serializer
.name of class used to serilaize the keys of records we will produce to Kafka

-value.serializer
.name of class used to serilaize the values of records we will produce to Kafka



Methods for sending messages
-Fire and Forget
.send message to server and don't really care if it arrives successfully or not

-Synchronous send
.checks to see if the message has been sucessfully delivered or not
.send() method return a Future object and we use get() to wait on the future and see if send() was successfull or not
.waits for acknowledgement signal from the reciever

-Asynchronous send
.we call send() method with a callback function which gets triggered when it recieves a response from the Kafka broker
.both parties involved can start and stop the communication as required by them



Cofiguring Producers
.server.properties is modified
.client-id:
	.a logical identifier for the client and the application it is used in
	.can be any string to be used by the brokers to identify messages sent from the client


.max.block.ms
.delivery.timeout.ms
.request.timeout.ms
.retries and retry.backoff.ms

.linger.ms:
	.time to wait for additional messages before sending the current batch

.compression.type:
	.can be set to gzip, lz4 or zstd in which corresponding compression algorithms will be used to comress the data before sending it to the broker
	.default is none

.batch.size:
	.controls the amount of memory in bytes that will be used for each batch

.max.in.flight.requests.per.connection
	.controls how many messages the producer will send to the server without recieving responses
	.setting high value can increase memory usage while improving throughput

.max.request.size
	.controls the size of a producer request sent by producer
	.caps both the size of largest message that can be sent and the number of messages that producer can send in one request

.acks
	.can have 3 values
		-acks=0
			.prdoucer will not wait for reply from the broker
			.this mean if something went wrong and broker did not recieve message, the producer will not know
		-acks=1
			.producer will recieve success response form the broker the moment leader replica recieved the message
		-acks=all
			.producer will recieve success response from the broker once all in-sync replicas recieved the message




Apache Avro
-data needs to be serialized before sending over the network
-serilization method used for serializing data for sending them over the network
-has JSON file format for describing the schema before sending
-that JSON file is sent to the recieving end to be used by deserializer to construct the schema of the data sent










CONSUMER
 consumer and consumer groups
 .consumer group contains a number of consumers
 .topic contains a number of paritions
 .let's assume there is consumer group G1 and topic T1
 .if a topic has 4 parition and only 2 consumer, each consumer will get 2 partiion of the topic
 .if a topic has 4 partition and 5 consumer, 4 consumers will each get a partition from the topic and 1 consumer will sit idly

 .now comes another consumer group G2 with 2 consumers subscribed to same topic T1
 .each consumer iof G2 will each recieve 2 partition from the topic irrespective of what is going on in G1

 .moving parition ownership from one consumer to another is called rebalance
 .rebalance is important because they provide the consumer group with high availability and scalability

.consumer must keep polling Kafka or the will be considered dead and the paritions they are consuming will be handed to another consumer on the group to continue consuming



-Configuring Consumers
.fetch.min.bytes: 
	.minimum amount of data it wants to recieve 
	.from the broker when fetching records

.fetch.max.wait.ms
	.how long to wait for data

.max.poll.interval.ms
	.length of time during which the consumer can go without polling befire it is considered dead

.request.timeout.ms
	.maximum time the consumer will wait for a reponse from the broker
	.if not respond within time limit, connection is closed and restarted

.enable.auto.commit 
	.controls whether consumer will commit offsets automatically and defaults to true


.client.id
	.used by brokers to identify messages from the client


Commits and offsets
.important while designing reliable consumers
.you can greatly customize the commits and offsets methods and techniques to acquire the best configuration suited for your use case
.automatic commit 
	.easiest way to commit offsets
	.allowing consumer to manage offsets for you
	.enable.auto.commit=true will cause consumer to commit the largest offset it recieved during 5 seconds interval


Asynchronous commit
.drawback of manual commit is that the applcation is blocked until the broker responds to the commit request
.another option is the asynchronous commit API
.here, we just send the request and continue on


Deserializers
.kafka consumers require deserializers to convert byte arryas recieved into Java objects


StandAlone Consumer: without a Group
.consumer can be subscribed to particular partitions instead of the whole topic
.other then lack of rebalances and the need to manually find the partitions everything else is similar to consumer in a group
.















